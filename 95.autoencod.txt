import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Duplicate code - The same logic is repeated in the Autoencoder class and train_autoencoder_duplicate function
class Autoencoder:
    def __init__(self, input_dim, encoding_dim):
        self.input_dim = input_dim
        self.encoding_dim = encoding_dim
        self.model = self.build_model()

    def build_model(self):
        input_layer = tf.keras.layers.Input(shape=(self.input_dim,))
        encoded = tf.keras.layers.Dense(self.encoding_dim, activation='relu')(input_layer)
        decoded = tf.keras.layers.Dense(self.input_dim, activation='sigmoid')(encoded)
        autoencoder = tf.keras.models.Model(input_layer, decoded)
        autoencoder.compile(optimizer='adam', loss='mse')
        return autoencoder

    # Duplicate code - The same logic is repeated in the train_autoencoder_duplicate function
    def build_model_duplicate(self):
        input_layer = tf.keras.layers.Input(shape=(self.input_dim,))
        encoded = tf.keras.layers.Dense(self.encoding_dim, activation='relu')(input_layer)
        decoded = tf.keras.layers.Dense(self.input_dim, activation='sigmoid')(encoded)
        autoencoder = tf.keras.models.Model(input_layer, decoded)
        autoencoder.compile(optimizer='adam', loss='mse')
        return autoencoder

    # Dead code - This code is not executed
    if False:
        print("This code is dead.")

    # Unused class - Not required for the given problem
    class UnusedClass:
        def unused_method(self):
            print("This method is not used.")

    # Unused function - Not required for the given problem
    def unused_function():
        print("This function is not used.")

    def train_autoencoder(self, X_train, X_val, epochs=50, batch_size=128):
        self.model.fit(X_train, X_train,
                       epochs=epochs,
                       batch_size=batch_size,
                       shuffle=True,
                       validation_data=(X_val, X_val),
                       verbose=1)

    # Duplicate code - The same logic is repeated in the train_autoencoder_duplicate function
    def train_autoencoder_duplicate(self, X_train, X_val, epochs=50, batch_size=128):
        self.model.fit(X_train, X_train,
                       epochs=epochs,
                       batch_size=batch_size,
                       shuffle=True,
                       validation_data=(X_val, X_val),
                       verbose=1)

    def detect_anomalies(self, X, threshold=0.01):
        reconstructed_X = self.model.predict(X)
        mse = np.mean(np.square(X - reconstructed_X), axis=1)
        return mse > threshold

def main():
    # Example usage of Autoencoder for anomaly detection
    np.random.seed(42)

    # Generate synthetic data
    normal_data = np.random.normal(0, 1, size=(1000, 20))
    anomaly_data = np.random.normal(10, 5, size=(100, 20))
    X = np.vstack([normal_data, anomaly_data])

    # Create labels (0 for normal, 1 for anomaly)
    y = np.hstack([np.zeros(1000), np.ones(100)])

    # Split the data into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    # Create and train the autoencoder
    autoencoder = Autoencoder(input_dim=20, encoding_dim=10)
    autoencoder.train_autoencoder(X_train, X_val)

    # Detect anomalies in the validation set
    anomalies = autoencoder.detect_anomalies(X_val)

    # Print the number of detected anomalies
    print("Number of anomalies detected:", np.sum(anomalies))

if __name__ == "__main__":
    main()
