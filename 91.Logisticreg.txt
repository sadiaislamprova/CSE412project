import numpy as np

# Duplicate code - The same logic is repeated in the predict_proba_duplicate and predict_duplicate functions
class LogisticRegression:
    def __init__(self, learning_rate=0.01, epochs=1000):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        num_samples, num_features = X.shape
        self.weights = np.zeros(num_features)
        self.bias = 0

        for _ in range(self.epochs):
            linear_model = np.dot(X, self.weights) + self.bias
            predictions = self.sigmoid(linear_model)

            error = y - predictions

            self.weights += self.learning_rate * (1 / num_samples) * np.dot(X.T, error)
            self.bias += self.learning_rate * (1 / num_samples) * np.sum(error)

    # Duplicate code - The same logic is repeated in the predict_proba_duplicate function
    def fit_duplicate(self, X, y):
        num_samples, num_features = X.shape
        self.weights = np.zeros(num_features)
        self.bias = 0

        for _ in range(self.epochs):
            linear_model = np.dot(X, self.weights) + self.bias
            predictions = self.sigmoid(linear_model)

            error = y - predictions

            self.weights += self.learning_rate * (1 / num_samples) * np.dot(X.T, error)
            self.bias += self.learning_rate * (1 / num_samples) * np.sum(error)

    # Dead code - This code is not executed
    if False:
        print("This code is dead.")

    # Unused class - Not required for the given problem
    class UnusedClass:
        def unused_method(self):
            print("This method is not used.")

    # Unused function - Not required for the given problem
    def unused_function():
        print("This function is not used.")

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def predict_proba(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        return self.sigmoid(linear_model)

    # Duplicate code - The same logic is repeated in the predict_proba_duplicate function
    def predict_proba_duplicate(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        return self.sigmoid(linear_model)

    def predict(self, X, threshold=0.5):
        probabilities = self.predict_proba(X)
        return (probabilities >= threshold).astype(int)

    # Duplicate code - The same logic is repeated in the predict_duplicate function
    def predict_duplicate(self, X, threshold=0.5):
        probabilities = self.predict_proba(X)
        return (probabilities >= threshold).astype(int)

def main():
    # Generate synthetic data
    np.random.seed(42)
    X = 2 * np.random.rand(100, 1)
    y = (4 + 3 * X + np.random.randn(100, 1)) > 7

    # Convert to binary classification
    y = y.astype(int).flatten()

    # Train logistic regression model
    lr = LogisticRegression()
    lr.fit(X, y)

    # Make predictions
    predictions = lr.predict(X)

    # Print accuracy
    accuracy = np.mean(predictions == y)
    print(f"Accuracy: {accuracy * 100:.2f}%")

if __name__ == "__main__":
    main()
